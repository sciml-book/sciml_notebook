{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINNs for static equilibrium problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import grad\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "class PINNStaticModel:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        \"\"\"Initialize the model and loss history.\"\"\"\n",
    "        self.model = torch.nn.Sequential(\n",
    "            torch.nn.Linear(input_dim, hidden_dim),\n",
    "            torch.nn.Tanh(),\n",
    "            torch.nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "        self.loss_history = {'total': [], 'boundary': [], 'differential': []}\n",
    "\n",
    "    def get_derivative(self, y, x):\n",
    "        \"\"\"Compute the derivative of y with respect to x.\"\"\"\n",
    "        dydx = grad(y, x, torch.ones(x.size()[0], 1),\n",
    "                    create_graph=True,\n",
    "                    retain_graph=True)[0]\n",
    "        return dydx\n",
    "\n",
    "    def compute_pinn_residual(self, x, EA, p):\n",
    "        \"\"\"Compute the residual of the governing differential equation.\"\"\"\n",
    "        u = self.model(x)\n",
    "        u_x = self.get_derivative(u, x)\n",
    "        EAu_xx = self.get_derivative(EA(x) * u_x, x)\n",
    "        f = EAu_xx + p(x)\n",
    "        return f\n",
    "\n",
    "    def compute_loss(self, x, EA, p):\n",
    "        \"\"\"\n",
    "        Compute boundary and differential equation losses.\n",
    "        - Boundary condition loss at x = 0 and x = 1.\n",
    "        - Differential equation loss as the mean squared error of the residual.\n",
    "        \"\"\"\n",
    "        # Boundary condition loss\n",
    "        u0_pred = self.model(torch.tensor([[0.0]]))\n",
    "        u1_pred = self.model(torch.tensor([[1.0]]))\n",
    "        MSE_b = (u0_pred - 0)**2 + (u1_pred - 0)**2\n",
    "\n",
    "        # Differential equation loss\n",
    "        f_pred = self.compute_pinn_residual(x, EA, p)\n",
    "        MSE_pde = torch.mean(f_pred**2)\n",
    "\n",
    "        return MSE_b, MSE_pde\n",
    "\n",
    "    def train(self, x, EA, p, epochs=50, lr=0.1):\n",
    "        \"\"\"\n",
    "        Train the model with LBFGS optimizer.\n",
    "        Track the progress using tqdm.\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.LBFGS(self.model.parameters(),\n",
    "                                      lr=lr,\n",
    "                                      max_iter=20,\n",
    "                                      max_eval=25,\n",
    "                                      tolerance_grad=1e-7,\n",
    "                                      tolerance_change=1e-9,\n",
    "                                      history_size=50)\n",
    "        pbar = tqdm(total=epochs, desc=\"Training\", position=0, leave=True)\n",
    "\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            MSE_b, MSE_pde = self.compute_loss(x, EA, p)\n",
    "            loss = MSE_b + MSE_pde\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update loss history\n",
    "            self.loss_history['total'].append(loss.item())\n",
    "            self.loss_history['boundary'].append(MSE_b.item())\n",
    "            self.loss_history['differential'].append(MSE_pde.item())\n",
    "            \n",
    "            # Update progress bar description with current losses\n",
    "            pbar.set_description(f\"Loss: {loss.item():.2e}\")\n",
    "            return loss\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            optimizer.step(closure)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    def plot_results(self, x):\n",
    "        \"\"\"Plot the model predictions and training loss history.\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Plot 1: Displacements\n",
    "        plt.subplot(1, 2, 1)\n",
    "        x_np = x.detach().numpy()\n",
    "        u_analytic = np.sin(2 * np.pi * x_np)\n",
    "        u_pred = self.model(x).detach().numpy()\n",
    "\n",
    "        plt.plot(x_np, u_analytic, 'r-', label='$u_{analytic}$')\n",
    "        plt.plot(x_np, u_pred, 'k--', label='$u_{pred}$')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('u(x)')\n",
    "        plt.title('Displacements')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot 2: Cost function history\n",
    "        plt.subplot(1, 2, 2)\n",
    "        epochs = range(len(self.loss_history['total']))\n",
    "        plt.semilogy(epochs, self.loss_history['total'], 'k-', label='Total cost')\n",
    "        plt.semilogy(epochs, self.loss_history['differential'], 'k--', label='Differential equation loss')\n",
    "        plt.semilogy(epochs, self.loss_history['boundary'], 'r-.', label='Boundary condition loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss function $\\mathcal{L}$')\n",
    "        plt.title('Loss function history')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "model = PINNStaticModel(input_dim=1, hidden_dim=10, output_dim=1)\n",
    "x = torch.linspace(0, 1, 100, requires_grad=True).view(-1, 1)\n",
    "EA = lambda x: 1 + 0 * x\n",
    "p = lambda x: 4 * math.pi**2 * torch.sin(2 * math.pi * x)\n",
    "\n",
    "print(\"Training PINN for static bar problem...\")\n",
    "\n",
    "# Training\n",
    "model.train(x, EA, p, epochs=50, lr=0.1)\n",
    "\n",
    "# Plot results\n",
    "model.plot_results(x)\n",
    "print(\"\\nFinal loss: {:.2e}\".format(model.loss_history['total'][-1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
