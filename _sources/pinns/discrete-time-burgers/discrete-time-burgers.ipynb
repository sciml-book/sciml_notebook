{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINNs: Discrete Time Burger's equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sciml-book/sciml_notebook/blob/main/pinns/discrete-time-burgers/discrete-time-burgers.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from typing import Tuple, List, Optional\n",
    "from functools import partial\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pyDOE import lhs\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"Neural network model for the PINNs implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size: int, output_size: int, hidden_layers: int, \n",
    "                 hidden_units: int, activation_function: nn.Module):\n",
    "        \"\"\"\n",
    "        Initialize the neural network.\n",
    "        \n",
    "        Args:\n",
    "            input_size: Number of input features\n",
    "            output_size: Number of output features\n",
    "            hidden_layers: Number of hidden layers\n",
    "            hidden_units: Number of units in each hidden layer\n",
    "            activation_function: Activation function to use\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_in = nn.Linear(input_size, hidden_units)\n",
    "        self.linear_out = nn.Linear(hidden_units, output_size)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Linear(hidden_units, hidden_units) for _ in range(hidden_layers)\n",
    "        ])\n",
    "        self.act = activation_function\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        x = self.linear_in(x)\n",
    "        for layer in self.layers:\n",
    "            x = self.act(layer(x))\n",
    "        return self.linear_out(x)\n",
    "\n",
    "class DiscreteTimePINNs:\n",
    "    \"\"\"Implementation of Physics-Informed Neural Networks for discrete time problems.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: dict):\n",
    "        \"\"\"\n",
    "        Initialize the DiscreteTimePINNs solver.\n",
    "        \n",
    "        Args:\n",
    "            config: Dictionary containing configuration parameters\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.setup_directories()\n",
    "        self.setup_data()\n",
    "        self.setup_model()\n",
    "        self.results = []\n",
    "        self.iter = 0\n",
    "\n",
    "    def setup_directories(self):\n",
    "        \"\"\"Create necessary directories for output.\"\"\"\n",
    "        directories = ['results']\n",
    "        for directory in directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    def setup_data(self):\n",
    "        \"\"\"Load and prepare data for training.\"\"\"\n",
    "        # Load Burgers equation data\n",
    "        data = scipy.io.loadmat(self.config['data_path'])\n",
    "        self.t = data['t'].flatten()[:, None]\n",
    "        self.x = data['x'].flatten()[:, None]\n",
    "        self.Exact = np.real(data['usol']).T.astype(np.float32)\n",
    "        \n",
    "        # Setup time steps and initial conditions\n",
    "        self.setup_time_steps()\n",
    "        self.setup_initial_conditions()\n",
    "        self.setup_irk_weights()\n",
    "        \n",
    "        # Convert data to tensors\n",
    "        self.prepare_tensors()\n",
    "\n",
    "    def setup_time_steps(self):\n",
    "        \"\"\"Setup time step information.\"\"\"\n",
    "        self.idx_t0 = self.config['idx_t0']\n",
    "        self.idx_t1 = self.config['idx_t1']\n",
    "        dt_value = self.t[self.idx_t1] - self.t[self.idx_t0]\n",
    "        self.dt = torch.tensor(dt_value, dtype=torch.float32)\n",
    "\n",
    "    def setup_initial_conditions(self):\n",
    "        \"\"\"Setup initial and boundary conditions.\"\"\"\n",
    "        N = self.config['N']\n",
    "        idx_x = np.random.choice(self.Exact.shape[1], N, replace=False)\n",
    "        self.x0 = self.x[idx_x, :]\n",
    "        self.u0 = self.Exact[self.idx_t0:self.idx_t0+1, idx_x].T\n",
    "        \n",
    "        # Add noise if specified\n",
    "        if self.config.get('noise_u0', 0.0) > 0:\n",
    "            self.u0 += (self.config['noise_u0'] * np.std(self.u0) * \n",
    "                       np.random.randn(*self.u0.shape))\n",
    "        \n",
    "        # Setup boundary conditions\n",
    "        self.x1 = np.vstack((self.config['lb'], self.config['ub']))\n",
    "        self.x_star = self.x\n",
    "\n",
    "    def setup_irk_weights(self):\n",
    "        \"\"\"Load and setup IRK weights.\"\"\"\n",
    "        tmp = np.loadtxt(\n",
    "            f\"./IRK_weights/Butcher_IRK{self.config['q']}.txt\", \n",
    "            ndmin=2\n",
    "        ).astype(np.float32)\n",
    "        weights = np.reshape(tmp[0:self.config['q']**2 + self.config['q']], \n",
    "                           (self.config['q']+1, self.config['q']))\n",
    "        self.IRK_weights = torch.tensor(weights, dtype=torch.float32).T\n",
    "\n",
    "    def prepare_tensors(self):\n",
    "        \"\"\"Convert numpy arrays to PyTorch tensors.\"\"\"\n",
    "        # Dictionary of numpy arrays that need to be converted to tensors\n",
    "        numpy_arrays = {\n",
    "            'x0': self.x0,\n",
    "            'x1': self.x1,\n",
    "            'u0': self.u0,\n",
    "            'x_star': self.x_star\n",
    "        }\n",
    "        \n",
    "        # Convert numpy arrays to tensors\n",
    "        for name, array in numpy_arrays.items():\n",
    "            tensor = torch.from_numpy(array).float().to(self.device)\n",
    "            if name in ['x0', 'x1', 'x_star']:\n",
    "                tensor.requires_grad = True\n",
    "            setattr(self, name, tensor)\n",
    "            \n",
    "        # Handle dt and IRK_weights separately as they're already tensors\n",
    "        self.dt = self.dt.to(self.device)\n",
    "        self.IRK_weights = self.IRK_weights.to(self.device)\n",
    "\n",
    "    def setup_model(self):\n",
    "        \"\"\"Initialize the neural network model.\"\"\"\n",
    "        self.model = NeuralNetwork(\n",
    "            input_size=1,\n",
    "            output_size=self.config['q'] + 1,\n",
    "            hidden_layers=4,\n",
    "            hidden_units=50,\n",
    "            activation_function=nn.Tanh()\n",
    "        ).float().to(self.device)\n",
    "        \n",
    "        self.model.apply(self.init_weights)\n",
    "\n",
    "    @staticmethod\n",
    "    def init_weights(m):\n",
    "        \"\"\"Initialize network weights using Xavier initialization.\"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_normal_(m.weight)\n",
    "            m.bias.data.fill_(0.0)\n",
    "\n",
    "    @staticmethod\n",
    "    def set_seed(seed: int = 42):\n",
    "        \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def f(self, x: torch.Tensor, x_1: torch.Tensor, \n",
    "          dt: torch.Tensor, IRK_weights: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Compute the physics-informed neural network function.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor\n",
    "            x_1: Boundary conditions tensor\n",
    "            dt: Time step\n",
    "            IRK_weights: IRK weights tensor\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of tensors (U0, U1)\n",
    "        \"\"\"\n",
    "        nu = 0.01/torch.pi\n",
    "        U1 = self.model(x)\n",
    "        U = U1[:, :-1]\n",
    "        \n",
    "        # Compute derivatives\n",
    "        U_x = self.fwd_gradients_0(U, x)\n",
    "        U_xx = self.fwd_gradients_0(U_x, x)\n",
    "        \n",
    "        # Compute physics terms\n",
    "        F = -U*U_x + nu*U_xx\n",
    "        U0 = U1 - dt * torch.matmul(F, IRK_weights)\n",
    "        U1 = self.model(x_1)\n",
    "        \n",
    "        return U0, U1\n",
    "\n",
    "    def compute_loss(self, x: torch.Tensor, x_1: torch.Tensor, \n",
    "                    dt: torch.Tensor, IRK_weights: torch.Tensor, \n",
    "                    U0_real: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute the total loss for training.\"\"\"\n",
    "        U0, U1 = self.f(x, x_1, dt, IRK_weights)\n",
    "        return torch.sum((U0_real - U0) ** 2) + torch.sum(U1 ** 2)\n",
    "\n",
    "    def closure(self, optimizer: torch.optim.Optimizer, x: torch.Tensor, \n",
    "                x_1: torch.Tensor, x_star: torch.Tensor, dt: torch.Tensor, \n",
    "                IRK_weights: torch.Tensor, U0_real: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Closure function for LBFGS optimizer.\"\"\"\n",
    "        optimizer.zero_grad()\n",
    "        loss = self.compute_loss(x, x_1, dt, IRK_weights, U0_real)\n",
    "        loss.backward(retain_graph=True)\n",
    "        \n",
    "        # Update iteration count and compute error\n",
    "        self.iter += 1\n",
    "        U1_pred = self.model(x_star)\n",
    "        pred = U1_pred[:, -1].detach().cpu().numpy()\n",
    "        error = np.linalg.norm(pred - self.Exact[self.idx_t1, :], 2) / \\\n",
    "                np.linalg.norm(self.Exact[self.idx_t1, :], 2)\n",
    "        \n",
    "        # Store results and save model if needed\n",
    "        self.results.append([self.iter, loss.item(), error])    \n",
    "        return loss\n",
    "\n",
    "    def train(self, num_iter: int):\n",
    "        \"\"\"Train using L-BFGS optimizer.\"\"\"\n",
    "        optimizer = torch.optim.LBFGS(\n",
    "            self.model.parameters(),\n",
    "            lr=1.0,\n",
    "            max_iter=num_iter,\n",
    "            max_eval=num_iter,\n",
    "            tolerance_grad=1e-7,\n",
    "            tolerance_change=1.0 * np.finfo(float).eps,\n",
    "            history_size=100,\n",
    "            line_search_fn='strong_wolfe'\n",
    "        )\n",
    "        \n",
    "        start_time = time.time()\n",
    "        closure_fn = partial(self.closure, optimizer, self.x0, self.x1, \n",
    "                            self.x_star, self.dt, self.IRK_weights, self.u0)\n",
    "        \n",
    "        with tqdm(total=num_iter, desc=\"LBFGS Training\", unit=\"iter\") as pbar:\n",
    "            def closure_with_tqdm():\n",
    "                loss = closure_fn()\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure_with_tqdm)\n",
    "            \n",
    "        self.lbfgs_training_time = time.time() - start_time\n",
    "        # Save final results\n",
    "        self.save_results()\n",
    "\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Save training results and model.\"\"\"\n",
    "        # Save training summary\n",
    "        total_time = getattr(self, 'lbfgs_training_time', 0)\n",
    "        \n",
    "        with open('results/burgers_discrete_time_training_summary.txt', 'w') as f:\n",
    "            f.write(f\"Total training time: {total_time:.6e} seconds\\n\")\n",
    "            f.write(f\"Total iterations: {self.iter}\\n\")\n",
    "            f.write(f\"Final Loss: {self.results[-1][1]:.6e}\\n\")\n",
    "            f.write(f\"Final L2: {self.results[-1][2]:.6e}\\n\")\n",
    "        \n",
    "        # Save training data\n",
    "        results_array = np.array(self.results)\n",
    "        np.savetxt(\"results/burgers_discrete_time_training_data.csv\", \n",
    "                   results_array, \n",
    "                   delimiter=\",\", \n",
    "                   header=\"Iter,Loss,L2\",\n",
    "                   comments=\"\")\n",
    "        \n",
    "        # Save final model\n",
    "        self.save_model('burgers_discrete_time.pt')\n",
    "\n",
    "    def save_model(self, path: str):\n",
    "        \"\"\"Save model state dict.\"\"\"\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path: str):\n",
    "        \"\"\"Load model state dict.\"\"\"\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "        self.model.eval()\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"Generate plots for the results.\"\"\"\n",
    "        # Create figure for training curves\n",
    "        self.plot_training_curves()\n",
    "        \n",
    "        # Create figure for solution visualization\n",
    "        self.plot_solution()\n",
    "\n",
    "    def plot_training_curves(self):\n",
    "        \"\"\"Plot training loss and L2 error curves.\"\"\"\n",
    "        data = pd.read_csv('results/burgers_discrete_time_training_data.csv')\n",
    "        \n",
    "        fig, axarr = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Loss plot\n",
    "        axarr[0].semilogy(data['Iter'], data['Loss'], \n",
    "                        label='Loss', color='gray', linewidth=1)\n",
    "        axarr[0].set_xlabel('Iteration')\n",
    "        axarr[0].set_ylabel('Loss')\n",
    "        \n",
    "        # L2 error plot\n",
    "        axarr[1].semilogy(data['Iter'], data['L2'], \n",
    "                        label='L2 Error', color='gray', linewidth=1)\n",
    "        axarr[1].set_xlabel('Iteration')\n",
    "        axarr[1].set_ylabel(r'$\\mathrm{L}_2$')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/burgers_discrete_time_training_curves.pdf')\n",
    "        plt.close()\n",
    "\n",
    "    def plot_solution(self):\n",
    "        \"\"\"Plot the solution, including exact solution and predictions.\"\"\"\n",
    "        fig = plt.figure(figsize=(12, 10))\n",
    "        fsize = 12\n",
    "        # Set up GridSpec\n",
    "        gs0 = gridspec.GridSpec(1, 2)\n",
    "        gs0.update(top=1-0.06, bottom=1-1/2 + 0.1, left=0.15, right=0.85, wspace=0)\n",
    "        gs1 = gridspec.GridSpec(1, 2)\n",
    "        gs1.update(top=1-1/2-0.05, bottom=0.15, left=0.15, right=0.85, wspace=0.5)\n",
    "        \n",
    "        # Plot exact solution\n",
    "        ax = plt.subplot(gs0[:, :])\n",
    "        h = ax.imshow(self.Exact.T, interpolation='nearest', cmap='rainbow',\n",
    "                        extent=[self.t.min(), self.t.max(), self.x.min(), self.x.max()],\n",
    "                        origin='lower', aspect='auto')\n",
    "        \n",
    "        # Add colorbar\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "        fig.colorbar(h, cax=cax)\n",
    "        \n",
    "        # Add time slice indicators\n",
    "        line = np.linspace(self.x.min(), self.x.max(), 2)[:, None]\n",
    "        # Fix scalar conversion by using item()\n",
    "        t0_scalar = self.t[self.idx_t0].item()\n",
    "        t1_scalar = self.t[self.idx_t1].item()\n",
    "        ax.plot(t0_scalar * np.ones((2,1)), line, 'w-', linewidth=1)\n",
    "        ax.plot(t1_scalar * np.ones((2,1)), line, 'w-', linewidth=1)\n",
    "        \n",
    "        ax.set_xlabel('$t$')\n",
    "        ax.set_ylabel('$x$')\n",
    "        ax.set_title('$u(t,x)$', fontsize=fsize)\n",
    "        \n",
    "        # Plot initial condition\n",
    "        ax = plt.subplot(gs1[0, 0])\n",
    "        ax.plot(self.x, self.Exact[self.idx_t0,:], 'b-', linewidth=2)\n",
    "        ax.plot(self.x0.cpu().detach().numpy(), self.u0, 'rx', linewidth=2, label='Data')\n",
    "        ax.set_xlabel('$x$')\n",
    "        ax.set_ylabel('$u(t,x)$')\n",
    "        ax.set_title('$t = %.2f$' % t0_scalar, fontsize=fsize)\n",
    "        ax.set_xlim([self.config['lb']-0.1, self.config['ub']+0.1])\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.3, -0.25), ncol=2, frameon=False)\n",
    "        \n",
    "        # Plot prediction vs exact solution\n",
    "        ax = plt.subplot(gs1[0, 1])\n",
    "        U1_pred = self.model(self.x_star)\n",
    "        U1_pred = U1_pred.cpu().detach().numpy()\n",
    "        \n",
    "        ax.plot(self.x, self.Exact[self.idx_t1,:], 'b-', linewidth=2, label='Exact')\n",
    "        ax.plot(self.x_star.cpu().detach().numpy(), U1_pred[:,-1], 'r--', \n",
    "                linewidth=2, label='Prediction')\n",
    "        ax.set_xlabel('$x$')\n",
    "        ax.set_ylabel('$u(t,x)$')\n",
    "        ax.set_title('$t = %.2f$' % t1_scalar, fontsize=fsize)\n",
    "        ax.set_xlim([self.config['lb']-0.1, self.config['ub']+0.1])\n",
    "        ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.25), ncol=2, frameon=False)\n",
    "        \n",
    "        plt.savefig('results/burgers_discrete_time.pdf')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    @staticmethod\n",
    "    def fwd_gradients_0(dy: torch.Tensor, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute forward gradients.\"\"\"\n",
    "        z = torch.ones(dy.shape, device=dy.device).requires_grad_()\n",
    "        g = torch.autograd.grad(dy, x, grad_outputs=z, create_graph=True)[0]\n",
    "        ones = torch.ones(g.shape, device=g.device)\n",
    "        return torch.autograd.grad(g, z, grad_outputs=ones, create_graph=True)[0]\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the DiscreteTimePINNs solver.\"\"\"\n",
    "    # Configuration dictionary\n",
    "    config = {\n",
    "        'data_path': './burgers_shock.mat',\n",
    "        'q': 500,\n",
    "        'N': 250,\n",
    "        'lb': np.array([-1.0]),\n",
    "        'ub': np.array([1.0]),\n",
    "        'idx_t0': 10,\n",
    "        'idx_t1': 90,\n",
    "        'noise_u0': 0.0\n",
    "    }\n",
    "    \n",
    "    # Set random seed\n",
    "    DiscreteTimePINNs.set_seed(42)\n",
    "    \n",
    "    # Initialize solver\n",
    "    solver = DiscreteTimePINNs(config)\n",
    "    \n",
    "    # Train the model\n",
    "    solver.train(num_iter=10000)\n",
    "    \n",
    "    # Plot results\n",
    "    solver.plot_results()\n",
    "    \n",
    "    # Print final error\n",
    "    U1_pred = solver.model(solver.x_star)\n",
    "    U1_pred = U1_pred.cpu().detach().numpy()\n",
    "    error = np.linalg.norm(U1_pred[:,-1] - solver.Exact[solver.idx_t1,:], 2) / \\\n",
    "            np.linalg.norm(solver.Exact[solver.idx_t1,:], 2)\n",
    "    print('Final Error: %e' % (error))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
